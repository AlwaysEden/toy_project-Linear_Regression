import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures

# 데이터셋을 가져오는 과정
train_data = pd.read_csv('/content/sample_data/california_housing_train.csv')
test_data = pd.read_csv('/content/sample_data/california_housing_test.csv')

#train set과 test set에서 입력값과 타깃값을 추출했음
train_target, test_target = train_data['median_house_value'].to_numpy(), test_data['median_house_value'].to_numpy()
train_input, test_input = train_data.drop('median_house_value', axis= 1), test_data.drop('median_house_value', axis= 1)
train_input, test_input = train_input.to_numpy(), test_input.to_numpy()

# train set에서 validation set을 추출했음
train_input, val_input, train_target, val_target = train_test_split(train_input, train_target, test_size = 0.2) 

#첫번째 학습 후 과소적합을 해결하기 위한 조치로 특성추출을 시도함
poly = PolynomialFeatures()
poly.fit(train_input)
train_poly = poly.transform(train_input)
test_poly = poly.transform(test_input)

# 첫번째 학습의 결정 계수 : train = 0.64, test = 0.61
# 두번째 학습의 결정 계수 : train = 0.70, test = 0.67 -> Feature engineering 적용한 후의 결과
lr = LinearRegression()
lr.fit(train_poly, train_target)
print(lr.score(train_poly, train_target))
print(lr.score(test_poly, test_target))



